{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9SIay2Wozg9"
   },
   "source": [
    "### 12.1 HTTP\n",
    "### 12.2 The world's simplest web browser\n",
    "- Wrong URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "65OF2SxXozhC",
    "outputId": "0a855e24-2564-4e44-e667-d83d02ccce06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 404 Not Found\r\n",
      "Date: Wed, 19 Jun 2019 17:57:02 GMT\r\n",
      "Server: Apache/2.4.18 (Ubuntu)\r\n",
      "Content-Length: 285\r\n",
      "Connection: close\r\n",
      "Content-Type: text/html; charset=iso-8859-1\r\n",
      "\r\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /remo.txt was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.18 (Ubuntu) Server at data.pr4e.org Port 80</address>\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((\"data.pr4e.org\",80))\n",
    "cmd = \"GET http://data.pr4e.org/remo.txt HTTP/1.0\\r\\n\\r\\n\".encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(20)\n",
    "    if(len(data)<1):\n",
    "        break\n",
    "    print(data.decode(),end=\"\")\n",
    "    \n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dU9usZriozhR"
   },
   "source": [
    "- Right URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "6aYljJNcozhS",
    "outputId": "483e18fb-a5c3-4073-ca0a-208434970d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\r\n",
      "Date: Wed, 19 Jun 2019 17:57:04 GMT\r\n",
      "Server: Apache/2.4.18 (Ubuntu)\r\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\r\n",
      "ETag: \"a7-54f6609245537\"\r\n",
      "Accept-Ranges: bytes\r\n",
      "Content-Length: 167\r\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\r\n",
      "Pragma: no-cache\r\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\r\n",
      "Connection: close\r\n",
      "Content-Type: text/plain\r\n",
      "\r\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((\"data.pr4e.org\",80))\n",
    "cmd = \"GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n\".encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(20)\n",
    "    if(len(data)<1):\n",
    "        break\n",
    "    print(data.decode(),end=\"\")\n",
    "    \n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsTUZi4qozhW"
   },
   "source": [
    "### 12.3 Retrieving an image over HTTP\n",
    "We accumulate the data in a string, trim off the headers, and then save the image data to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "id": "rgjnSUXuozhX",
    "outputId": "89272c76-4fa6-4d98-b16a-3aee97aba75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 5120\n",
      "5120 10240\n",
      "5120 15360\n",
      "5120 20480\n",
      "5120 25600\n",
      "5120 30720\n",
      "5120 35840\n",
      "5120 40960\n",
      "5120 46080\n",
      "5120 51200\n",
      "5120 56320\n",
      "5120 61440\n",
      "5120 66560\n",
      "5120 71680\n",
      "5120 76800\n",
      "5120 81920\n",
      "5120 87040\n",
      "5120 92160\n",
      "5120 97280\n",
      "5120 102400\n",
      "5120 107520\n",
      "5120 112640\n",
      "5120 117760\n",
      "5120 122880\n",
      "5120 128000\n",
      "5120 133120\n",
      "5120 138240\n",
      "5120 143360\n",
      "5120 148480\n",
      "5120 153600\n",
      "5120 158720\n",
      "5120 163840\n",
      "5120 168960\n",
      "5120 174080\n",
      "5120 179200\n",
      "5120 184320\n",
      "5120 189440\n",
      "5120 194560\n",
      "5120 199680\n",
      "5120 204800\n",
      "5120 209920\n",
      "5120 215040\n",
      "5120 220160\n",
      "5120 225280\n",
      "5120 230400\n",
      "208 230608\n",
      "Header length 394\n",
      "HTTP/1.1 200 OK\n",
      "Date: Wed, 19 Jun 2019 17:57:07 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Mon, 15 May 2017 12:27:40 GMT\n",
      "ETag: \"38342-54f8f2e5b6277\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 230210\n",
      "Vary: Accept-Encoding\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: image/jpeg\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import time\n",
    "\n",
    "HOST = \"data.pr4e.org\"\n",
    "PORT = 80\n",
    "mysock = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
    "mysock.connect((HOST,PORT))\n",
    "mysock.sendall(b\"GET http://data.pr4e.org/cover3.jpg HTTP/1.0\\r\\n\\r\\n\")\n",
    "count = 0\n",
    "picture = b\"\"\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(5120)\n",
    "    if(len(data)<1):break\n",
    "    time.sleep(0.25)\n",
    "    count = count + len(data)\n",
    "    print(len(data),count)\n",
    "    picture = picture + data\n",
    "    \n",
    "mysock.close()\n",
    "\n",
    "# Look for the end of the header\n",
    "pos = picture.find(b\"\\r\\n\\r\\n\")\n",
    "print(\"Header length\", pos)\n",
    "print(picture[:pos].decode())\n",
    "\n",
    "# Skip past the header and save the picture data\n",
    "picture = picture[pos+4:]\n",
    "fhand = open(\"files\\stuff.jpg\", \"wb\")\n",
    "fhand.write(picture)\n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKGhPfbqozhb"
   },
   "source": [
    "### 12.4 Retrieving web pages with urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "zUeNLB8Hozhc",
    "outputId": "15c73937-6dc4-4522-b144-8fc209c575f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "fhand = urllib.request.urlopen(\"http://data.pr4e.org/romeo.txt\")\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kne4kKvKozhf"
   },
   "source": [
    "### 12.5 Parsing HTML and scraping the web\n",
    "### 12.6 Parsing HTML using regular expressions\n",
    " http://www.dr-chuck.com/page1.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PROnckwJozhg",
    "outputId": "5f9739c0-36a3-4ddc-c382-fe694c505d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter -  http://www.dr-chuck.com/page1.htm\n",
      "http://www.dr-chuck.com/page2.htm\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import re\n",
    "url = input(\"Enter - \")\n",
    "html = urllib.request.urlopen(url).read()\n",
    "links = re.findall(b'href=\"(http://.*?)\"',html)\n",
    "for link in links:\n",
    "    print(link.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-O0_Xckw4l3P"
   },
   "source": [
    "### 12.7 Parsing HTML using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "SI6cnZb2ozhi",
    "outputId": "92c72b39-6c51-484f-f664-9a5c90e642bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter -  http://www.dr-chuck.com/page1.htm\n",
      "http://www.dr-chuck.com/page2.htm\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate error\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input(\"Enter - \")\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve all of the anchor tages\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "  print(tag.get(\"href\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "SaSlV0K_pqCN",
    "outputId": "d9410459-eb00-4907-e723-66e37b07d545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter -  http://www.dr-chuck.com/page1.htm\n",
      "TAG: <a href=\"http://www.dr-chuck.com/page2.htm\">\n",
      "Second Page</a>\n",
      "URL: http://www.dr-chuck.com/page2.htm\n",
      "Contents: \n",
      "Second Page\n",
      "Attrs: {'href': 'http://www.dr-chuck.com/page2.htm'}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate error\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input(\"Enter - \")\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve all of the anchor tages\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "  print('TAG:',tag)\n",
    "  print(\"URL:\",tag.get(\"href\",None))\n",
    "  print(\"Contents:\",tag.contents[0])\n",
    "  print(\"Attrs:\",tag.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e625A_vDtWYO"
   },
   "source": [
    "### 12.8 Reading binary files using urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "W4biHwVh4l3Z",
    "outputId": "c63de929-2efd-4a30-ae6c-3c90c1ce5c4d"
   },
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "img = urllib.request.urlopen(\"http://data.pr4e.org/cover3.jpg\").read()\n",
    "fhand = open(\"files/cover3.jpg\",\"wb\")\n",
    "fhand.write(img)\n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "Y_T3SStC4l3b",
    "outputId": "3076d76e-5b82-4f07-c9eb-7185cbc8d1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230210 characters copied\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "img = urllib.request.urlopen(\"http://data.pr4e.org/cover3.jpg\")\n",
    "fhand = open(\"files/cover3.jpg\",\"wb\")\n",
    "\n",
    "size=0\n",
    "while True:\n",
    "    info = img.read(100000)\n",
    "    if len(info)<1:break\n",
    "    size = size+len(info)\n",
    "    fhand.write(info)\n",
    "        \n",
    "print(size,\"characters copied\")\n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lN5RXuGw4l3f"
   },
   "source": [
    "### 12.9 Glossary\n",
    "### 12.10 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "NNSAxpO04l3f",
    "outputId": "02c93ede-4080-4ddb-c317-460a7eb25e26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\r\n",
      "Date: Wed, 19 Jun 2019 17:59:10 GMT\r\n",
      "Server: Apache/2.4.18 (Ubuntu)\r\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\r\n",
      "ETag: \"1d3-54f6609240717\"\r\n",
      "Accept-Ranges: bytes\r\n",
      "Content-Length: 467\r\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\r\n",
      "Pragma: no-cache\r\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\r\n",
      "Connection: close\r\n",
      "Content-Type: text/plain\r\n",
      "\r\n",
      "Why should you learn to write programs?\n",
      "\n",
      "Writing programs (or programming) is a very creative \n",
      "and rewarding activity.  You can write programs for \n",
      "many reasons, ranging from making your living to solving\n",
      "a difficult data analysis problem to having fun to helping\n",
      "someone else solve a problem.  This book assumes that \n",
      "everyone needs to know how to program, and that once \n",
      "you know how to program you will figure out what you want \n",
      "to do with your newfound skills.  \n"
     ]
    }
   ],
   "source": [
    "#web1\n",
    "import socket\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((\"data.pr4e.org\",80))\n",
    "cmd = \"GET http://data.pr4e.org/intro-short.txt HTTP/1.0\\r\\n\\r\\n\".encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(20)\n",
    "    if(len(data)<1):\n",
    "        break\n",
    "    print(data.decode(),end=\"\")\n",
    "    \n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "HROXSytD4l3i",
    "outputId": "3a586c12-225b-4fe3-8c9f-909d7e192590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter - http://py4e-data.dr-chuck.net/comments_216870.html\n",
      "50\n",
      "2664\n"
     ]
    }
   ],
   "source": [
    "# Web2\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate error\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input(\"Enter - \")\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "count=0\n",
    "sum = 0\n",
    "# Retrieve all of the anchor tages\n",
    "tags = soup('span')\n",
    "for tag in tags:\n",
    "  #print(tag.contents)\n",
    "  sum = int(tag.contents[0])+sum\n",
    "  count = count+1\n",
    "\n",
    "print(count)\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "6Dbg_ywj4l3k",
    "outputId": "0c0f8192-7feb-4214-eede-0406098e1b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter -  http://py4e-data.dr-chuck.net/known_by_Jared.html\n",
      "Enter count: 7\n",
      "Enter position: 18\n",
      "http://py4e-data.dr-chuck.net/known_by_Suilven.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Lavena.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Koden.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Khairah.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Aristomenis.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Zuzia.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Hong.html\n"
     ]
    }
   ],
   "source": [
    "# Web3\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "count = int(input(\"Enter count: \"))\n",
    "position =int(input(\"Enter position: \"))-1\n",
    "\n",
    "while count:\n",
    "  html = urllib.request.urlopen(url, context=ctx).read()\n",
    "  soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "  # Retrieve all of the anchor tags\n",
    "  count = count-1\n",
    "  tags = soup('a')\n",
    "  url=tags[position].get(\"href\",None)\n",
    "  print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Chapter_12_Networked_Programs.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
